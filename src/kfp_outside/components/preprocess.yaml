# PIPELINE DEFINITION
# Name: preprocess
# Inputs:
#    bucket_name: str
#    data_version: str [Default: 'v1']
#    dest_test_object: str
#    dest_train_object: str
#    minio_access_key: str
#    minio_endpoint: str
#    minio_secret_key: str
#    n_features_to_select: str [Default: 'auto']
#    test_csv: system.Dataset
#    train_csv: system.Dataset
# Outputs:
#    test_key: str
#    train_key: str
#    transformer_joblib: system.Model
components:
  comp-preprocess:
    executorLabel: exec-preprocess
    inputDefinitions:
      artifacts:
        test_csv:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        train_csv:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        bucket_name:
          parameterType: STRING
        data_version:
          defaultValue: v1
          isOptional: true
          parameterType: STRING
        dest_test_object:
          parameterType: STRING
        dest_train_object:
          parameterType: STRING
        minio_access_key:
          parameterType: STRING
        minio_endpoint:
          parameterType: STRING
        minio_secret_key:
          parameterType: STRING
        n_features_to_select:
          defaultValue: auto
          isOptional: true
          parameterType: STRING
    outputDefinitions:
      artifacts:
        transformer_joblib:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
      parameters:
        test_key:
          parameterType: STRING
        train_key:
          parameterType: STRING
deploymentSpec:
  executors:
    exec-preprocess:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - preprocess
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'protobuf==4.25.5'\
          \ 'kfp==2.12.1' 'fastapi==0.104.1' 'uvicorn[standard]==0.24.0' 'loguru==0.7.2'\
          \ 'joblib==1.3.2' 'pandas==2.1.3' 'pytest==7.4.3' 'numpy==1.24.4' 'mlflow==2.8.1'\
          \ 'matplotlib==3.8.1' 'pydantic==1.10.8' 'ortools==9.7.2996' 'requests==2.31.0'\
          \ 'boto3' 'shap' 'optuna' 'optbinning' 'urllib3' 'minio' 'lightgbm' 'python-dotenv'\
          \ && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef preprocess(\n    train_csv: InputPath(Dataset),       \n    test_csv:\
          \  InputPath(Dataset),   \n    transformer_joblib: Output[Model],    \n\
          \    minio_endpoint: str,\n    minio_access_key: str,\n    minio_secret_key:\
          \ str,\n    bucket_name: str,\n    dest_train_object: str,\n    dest_test_object:\
          \ str,\n    n_features_to_select: str = \"auto\",\n    data_version: str\
          \ = \"v1\",\n) -> NamedTuple(\"Keys\", [(\"train_key\", str), (\"test_key\"\
          , str)]):\n    import pandas as pd, numpy as np, joblib\n    from pathlib\
          \ import Path\n    from minio import Minio\n    from optbinning import BinningProcess\n\
          \    from sklearn.feature_selection import SelectKBest, f_classif\n\n  \
          \  # Load artifact CSVs\n    df_tr = pd.read_csv(train_csv)\n    df_te =\
          \ pd.read_csv(test_csv)\n\n    # 2) IV\u2011based filter & binning\n   \
          \ def get_lists(df):\n        num = df.select_dtypes(include=[\"int64\"\
          ,\"float64\"]).columns.tolist()\n        cat = df.select_dtypes(include=[\"\
          object\"]).columns.tolist()\n        for c in (\"SK_ID_CURR\",\"TARGET\"\
          ):\n            if c in num: num.remove(c)\n        return cat, num\n\n\
          \    def iv_score(bins, y):\n        tmp = pd.DataFrame({\"b\": bins, \"\
          t\": y})\n        tot_g, tot_b = (tmp.t==0).sum(), (tmp.t==1).sum()\n  \
          \      s = 0\n        for _, g in tmp.groupby(\"b\"):\n            good\
          \ = (g.t==0).sum() or 0.5\n            bad  = (g.t==1).sum() or 0.5\n  \
          \          s += (good/tot_g - bad/tot_b)*np.log((good/tot_g)/(bad/tot_b))\n\
          \        return s\n\n    cat_cols, num_cols = get_lists(df_tr)\n    y =\
          \ df_tr[\"TARGET\"]\n    X_tr, X_te = df_tr.drop(\"TARGET\", axis=1), df_te.copy()\n\
          \n    survivors = []\n    for f in cat_cols+num_cols:\n        bp_tmp =\
          \ BinningProcess([f], categorical_variables=[f] if f in cat_cols else [])\n\
          \        bp_tmp.fit(X_tr[[f]].values, y)\n        b = bp_tmp.transform(X_tr[[f]].values).flatten()\n\
          \        if 0.02 <= iv_score(b,y) <= 0.5 and X_tr[f].isna().mean()<=0.1:\n\
          \            survivors.append(f)\n\n    bp = BinningProcess(variable_names=survivors,\n\
          \                        categorical_variables=[c for c in survivors if\
          \ c in cat_cols])\n    bp.fit(X_tr[survivors].values, y)\n\n    df_tr_b\
          \ = pd.DataFrame(bp.transform(X_tr[survivors].values), columns=survivors)\n\
          \    df_te_b = pd.DataFrame(bp.transform(X_te[survivors].values), columns=survivors)\n\
          \n    # 3) SelectKBest\n    k = len(survivors) if n_features_to_select==\"\
          auto\" else int(n_features_to_select)\n    sel = SelectKBest(f_classif,\
          \ k=k)\n    sel.fit(df_tr_b.fillna(0), y)\n\n    keep = df_tr_b.columns[sel.get_support()]\n\
          \    out_tr = pd.DataFrame(sel.transform(df_tr_b), columns=keep)\n    out_te\
          \ = pd.DataFrame(sel.transform(df_te_b), columns=keep)\n    out_tr[\"TARGET\"\
          ] = y\n\n    # Dump transformer\n    Path(transformer_joblib.path).parent.mkdir(parents=True,\
          \ exist_ok=True)\n    joblib.dump({\"binning_process\": bp, \"selector\"\
          : sel}, transformer_joblib.path)\n\n    # Push processed CSVs back to MinIO\n\
          \    client = Minio(\n        minio_endpoint,\n        access_key=minio_access_key,\n\
          \        secret_key=minio_secret_key,\n        secure=False,\n    )\n  \
          \  tr_key = dest_train_object.replace(\".csv\", f\"_{data_version}.csv\"\
          )\n    te_key = dest_test_object.replace(\".csv\", f\"_{data_version}.csv\"\
          )\n    tmp_tr = f\"/tmp/{Path(tr_key).name}\"\n    tmp_te = f\"/tmp/{Path(te_key).name}\"\
          \n    out_tr.to_csv(tmp_tr, index=False)\n    out_te.to_csv(tmp_te, index=False)\n\
          \    client.fput_object(bucket_name, tr_key, tmp_tr)\n    client.fput_object(bucket_name,\
          \ te_key, tmp_te)\n\n    return (tr_key, te_key)\n\n"
        image: microwave1005/scipy-img:latest
pipelineInfo:
  name: preprocess
root:
  dag:
    outputs:
      artifacts:
        transformer_joblib:
          artifactSelectors:
          - outputArtifactKey: transformer_joblib
            producerSubtask: preprocess
      parameters:
        test_key:
          valueFromParameter:
            outputParameterKey: test_key
            producerSubtask: preprocess
        train_key:
          valueFromParameter:
            outputParameterKey: train_key
            producerSubtask: preprocess
    tasks:
      preprocess:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-preprocess
        inputs:
          artifacts:
            test_csv:
              componentInputArtifact: test_csv
            train_csv:
              componentInputArtifact: train_csv
          parameters:
            bucket_name:
              componentInputParameter: bucket_name
            data_version:
              componentInputParameter: data_version
            dest_test_object:
              componentInputParameter: dest_test_object
            dest_train_object:
              componentInputParameter: dest_train_object
            minio_access_key:
              componentInputParameter: minio_access_key
            minio_endpoint:
              componentInputParameter: minio_endpoint
            minio_secret_key:
              componentInputParameter: minio_secret_key
            n_features_to_select:
              componentInputParameter: n_features_to_select
        taskInfo:
          name: preprocess
  inputDefinitions:
    artifacts:
      test_csv:
        artifactType:
          schemaTitle: system.Dataset
          schemaVersion: 0.0.1
      train_csv:
        artifactType:
          schemaTitle: system.Dataset
          schemaVersion: 0.0.1
    parameters:
      bucket_name:
        parameterType: STRING
      data_version:
        defaultValue: v1
        isOptional: true
        parameterType: STRING
      dest_test_object:
        parameterType: STRING
      dest_train_object:
        parameterType: STRING
      minio_access_key:
        parameterType: STRING
      minio_endpoint:
        parameterType: STRING
      minio_secret_key:
        parameterType: STRING
      n_features_to_select:
        defaultValue: auto
        isOptional: true
        parameterType: STRING
  outputDefinitions:
    artifacts:
      transformer_joblib:
        artifactType:
          schemaTitle: system.Model
          schemaVersion: 0.0.1
    parameters:
      test_key:
        parameterType: STRING
      train_key:
        parameterType: STRING
schemaVersion: 2.1.0
sdkVersion: kfp-2.12.1
