# PIPELINE DEFINITION
# Name: preprocess
# Inputs:
#    data_version: str
#    dest_test_object: str
#    dest_train_object: str
#    experiment_name: str
#    minio_access_key: str
#    minio_endpoint: str
#    minio_secret_key: str
#    mlflow_endpoint: str
#    model_name: str
#    n_features_to_select: str
#    test_csv: system.Dataset
#    train_csv: system.Dataset
#    version: str
# Outputs:
#    mlflow_run_id: system.Artifact
#    output_test_csv: system.Dataset
#    output_train_csv: system.Dataset
#    transformer_joblib: system.Artifact
components:
  comp-preprocess:
    executorLabel: exec-preprocess
    inputDefinitions:
      artifacts:
        test_csv:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        train_csv:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        data_version:
          parameterType: STRING
        dest_test_object:
          parameterType: STRING
        dest_train_object:
          parameterType: STRING
        experiment_name:
          parameterType: STRING
        minio_access_key:
          parameterType: STRING
        minio_endpoint:
          parameterType: STRING
        minio_secret_key:
          parameterType: STRING
        mlflow_endpoint:
          parameterType: STRING
        model_name:
          parameterType: STRING
        n_features_to_select:
          parameterType: STRING
        version:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        mlflow_run_id:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        output_test_csv:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        output_train_csv:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        transformer_joblib:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
deploymentSpec:
  executors:
    exec-preprocess:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - preprocess
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef preprocess(\n    train_csv: Input[Dataset],\n    test_csv: Input[Dataset],\n\
          \    transformer_joblib: Output[Artifact],\n    output_train_csv: Output[Dataset],\n\
          \    output_test_csv: Output[Dataset],\n    mlflow_run_id: Output[Artifact],\n\
          \    minio_endpoint: str,\n    minio_access_key: str,\n    minio_secret_key:\
          \ str,\n    mlflow_endpoint: str,\n    dest_train_object: str,\n    dest_test_object:\
          \ str,\n    n_features_to_select: str,\n    data_version: str,\n    model_name:\
          \ str,\n    version: str,\n    experiment_name: str,\n) :\n\n    import\
          \ os\n    import pandas as pd \n    import numpy as np\n    import joblib\n\
          \    from pathlib import Path\n    import mlflow\n    from optbinning import\
          \ BinningProcess\n    from sklearn.feature_selection import SelectKBest,\
          \ f_classif\n\n    os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = f\"http://{minio_endpoint}\"\
          \n    os.environ[\"AWS_ACCESS_KEY_ID\"] = minio_access_key\n    os.environ[\"\
          AWS_SECRET_ACCESS_KEY\"] = minio_secret_key\n    os.environ[\"MLFLOW_ENDPOINT\"\
          ] = f\"http://{mlflow_endpoint}\"\n    # Load data\n\n    df_train = pd.read_csv(train_csv.path)\n\
          \    df_test = pd.read_csv(test_csv.path)\n\n    # Data processing functions\n\
          \    def get_lists(df):\n        numeric = df.select_dtypes(include=[\"\
          int64\",\"float64\"]).columns.tolist()\n        category = df.select_dtypes(include=[\"\
          object\"]).columns.tolist()\n        for column in (\"SK_ID_CURR\",\"TARGET\"\
          ):\n            if column in numeric:\n                numeric.remove(column)\n\
          \        return category, numeric\n\n    def iv_score(bins, y):\n      \
          \  df = pd.DataFrame({\"bins\": bins, \"target\": y})\n        total_good,\
          \ total_bad = (df.target==0).sum(), (df.target==1).sum()\n        score\
          \ = 0\n        for _, goods in df.groupby(\"bins\"):\n            good =\
          \ (goods.target == 0).sum() or 0.5\n            bad = (goods.target == 1).sum()\
          \ or 0.5\n            score += (good / total_good - bad / total_bad) * np.log((good\
          \ / total_good) / (bad / total_bad))\n        return score\n\n    # Feature\
          \ selection and binning\n    cat_cols, num_cols = get_lists(df_train)\n\
          \    y = df_train[\"TARGET\"]\n    X_tr, X_te = df_train.drop(\"TARGET\"\
          , axis=1), df_test.copy()\n\n    survivors = []\n    for f in cat_cols+num_cols:\n\
          \        binning = BinningProcess([f], categorical_variables=[f] if f in\
          \ cat_cols else [])\n        binning.fit(X_tr[[f]].values, y)\n        b\
          \ = binning.transform(X_tr[[f]].values).flatten()\n        if 0.02 <= iv_score(b,y)\
          \ <= 0.5 and X_tr[f].isna().mean()<=0.1:\n            survivors.append(f)\n\
          \n    opt_binning_process = BinningProcess(variable_names=survivors,\n \
          \                       categorical_variables=[col for col in survivors\
          \ if col in cat_cols])\n    opt_binning_process.fit(X_tr[survivors].values,\
          \ y)\n\n    df_train_binned = pd.DataFrame(opt_binning_process.transform(X_tr[survivors].values),\
          \ columns=survivors)\n    df_test_binned = pd.DataFrame(opt_binning_process.transform(X_te[survivors].values),\
          \ columns=survivors)\n\n    # Feature selection\n    k = len(survivors)\
          \ if n_features_to_select==\"auto\" else int(n_features_to_select)\n   \
          \ selector = SelectKBest(f_classif, k=k)\n    selector.fit(df_train_binned.fillna(0),\
          \ y)\n\n    keep = df_train_binned.columns[selector.get_support()]\n   \
          \ out_tr = pd.DataFrame(selector.transform(df_train_binned), columns=keep)\n\
          \    out_te = pd.DataFrame(selector.transform(df_train_binned), columns=keep)\n\
          \    out_tr[\"TARGET\"] = y\n\n    # Save artifacts to KFP component outputs\n\
          \    Path(transformer_joblib.path).parent.mkdir(parents=True, exist_ok=True)\n\
          \    joblib.dump(\n        {\"opt_binning_process\": opt_binning_process,\
          \ \"selector\": selector},\n        transformer_joblib.path,\n    )\n  \
          \  out_tr.to_csv(output_train_csv.path, index=False)\n    out_te.to_csv(output_test_csv.path,\
          \ index=False)\n\n    # Prepare artifact names for MLflow\n    train_artifact_name\
          \ = dest_train_object.replace(\".csv\", f\"_{data_version}.csv\")\n    test_artifact_name\
          \ = dest_test_object.replace(\".csv\", f\"_{data_version}.csv\")\n    transformer_artifact_name\
          \ = f\"transformer_{data_version}.joblib\"\n\n    # Create temporary directory\
          \ for MLflow artifacts\n    art_dir = Path(\"/tmp/mlflow_artifacts\")\n\
          \    art_dir.mkdir(parents=True, exist_ok=True)\n\n    # Save artifacts\
          \ with versioned names\n    joblib.dump(\n        {\"opt_binning_process\"\
          : opt_binning_process, \"selector\": selector},\n        art_dir / transformer_artifact_name,\n\
          \    )\n    out_tr.to_csv(art_dir / train_artifact_name, index=False)\n\
          \    out_te.to_csv(art_dir / test_artifact_name, index=False)\n\n    # Log\
          \ to MLflow\n    mlflow.set_tracking_uri(os.environ[\"MLFLOW_ENDPOINT\"\
          ])\n    mlflow.set_experiment(experiment_name)\n\n    with mlflow.start_run(run_name=\"\
          preproc_run\",) as parent:\n\n        parent_id = parent.info.run_id\n \
          \       joblib.dump(\n            {\"opt_binning_process\": opt_binning_process,\
          \ \"selector\": selector},\n            transformer_joblib.path,\n     \
          \   )\n        out_tr.to_csv(output_train_csv.path, index=False)\n     \
          \   out_te.to_csv(output_test_csv.path, index=False)\n\n        mlflow.log_artifact(transformer_joblib.path,\
          \ artifact_path=\"prep\")\n        mlflow.log_artifact(output_train_csv.path,\
          \ artifact_path=\"prep\")\n        mlflow.log_artifact(output_test_csv.path,\
          \ artifact_path=\"prep\")\n\n    Path(mlflow_run_id.path).parent.mkdir(parents=True,\
          \ exist_ok=True)\n    Path(mlflow_run_id.path).write_text(parent_id)\n\n"
        image: microwave1005/scipy-img:latest
pipelineInfo:
  name: preprocess
root:
  dag:
    outputs:
      artifacts:
        mlflow_run_id:
          artifactSelectors:
          - outputArtifactKey: mlflow_run_id
            producerSubtask: preprocess
        output_test_csv:
          artifactSelectors:
          - outputArtifactKey: output_test_csv
            producerSubtask: preprocess
        output_train_csv:
          artifactSelectors:
          - outputArtifactKey: output_train_csv
            producerSubtask: preprocess
        transformer_joblib:
          artifactSelectors:
          - outputArtifactKey: transformer_joblib
            producerSubtask: preprocess
    tasks:
      preprocess:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-preprocess
        inputs:
          artifacts:
            test_csv:
              componentInputArtifact: test_csv
            train_csv:
              componentInputArtifact: train_csv
          parameters:
            data_version:
              componentInputParameter: data_version
            dest_test_object:
              componentInputParameter: dest_test_object
            dest_train_object:
              componentInputParameter: dest_train_object
            experiment_name:
              componentInputParameter: experiment_name
            minio_access_key:
              componentInputParameter: minio_access_key
            minio_endpoint:
              componentInputParameter: minio_endpoint
            minio_secret_key:
              componentInputParameter: minio_secret_key
            mlflow_endpoint:
              componentInputParameter: mlflow_endpoint
            model_name:
              componentInputParameter: model_name
            n_features_to_select:
              componentInputParameter: n_features_to_select
            version:
              componentInputParameter: version
        taskInfo:
          name: preprocess
  inputDefinitions:
    artifacts:
      test_csv:
        artifactType:
          schemaTitle: system.Dataset
          schemaVersion: 0.0.1
      train_csv:
        artifactType:
          schemaTitle: system.Dataset
          schemaVersion: 0.0.1
    parameters:
      data_version:
        parameterType: STRING
      dest_test_object:
        parameterType: STRING
      dest_train_object:
        parameterType: STRING
      experiment_name:
        parameterType: STRING
      minio_access_key:
        parameterType: STRING
      minio_endpoint:
        parameterType: STRING
      minio_secret_key:
        parameterType: STRING
      mlflow_endpoint:
        parameterType: STRING
      model_name:
        parameterType: STRING
      n_features_to_select:
        parameterType: STRING
      version:
        parameterType: STRING
  outputDefinitions:
    artifacts:
      mlflow_run_id:
        artifactType:
          schemaTitle: system.Artifact
          schemaVersion: 0.0.1
      output_test_csv:
        artifactType:
          schemaTitle: system.Dataset
          schemaVersion: 0.0.1
      output_train_csv:
        artifactType:
          schemaTitle: system.Dataset
          schemaVersion: 0.0.1
      transformer_joblib:
        artifactType:
          schemaTitle: system.Artifact
          schemaVersion: 0.0.1
schemaVersion: 2.1.0
sdkVersion: kfp-2.12.1
