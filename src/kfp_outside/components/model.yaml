# PIPELINE DEFINITION
# Name: modeling
# Inputs:
#    experiment_name: str [Default: 'UnderwritingPipeline']
#    minio_access_key: str
#    minio_endpoint: str
#    minio_secret_key: str
#    model_name: str [Default: 'xgb']
#    test_csv: system.Dataset
#    train_csv: system.Dataset
#    version: str [Default: 'v1']
# Outputs:
#    model_joblib: system.Model
#    registered_model: str
components:
  comp-modeling:
    executorLabel: exec-modeling
    inputDefinitions:
      artifacts:
        test_csv:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        train_csv:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        experiment_name:
          defaultValue: UnderwritingPipeline
          isOptional: true
          parameterType: STRING
        minio_access_key:
          parameterType: STRING
        minio_endpoint:
          parameterType: STRING
        minio_secret_key:
          parameterType: STRING
        model_name:
          defaultValue: xgb
          isOptional: true
          parameterType: STRING
        version:
          defaultValue: v1
          isOptional: true
          parameterType: STRING
    outputDefinitions:
      artifacts:
        model_joblib:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
      parameters:
        registered_model:
          parameterType: STRING
deploymentSpec:
  executors:
    exec-modeling:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - modeling
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'protobuf==4.25.5'\
          \ 'kfp==2.12.1' 'fastapi==0.104.1' 'uvicorn[standard]==0.24.0' 'loguru==0.7.2'\
          \ 'joblib==1.3.2' 'pandas==2.1.3' 'pytest==7.4.3' 'numpy==1.24.4' 'mlflow==2.8.1'\
          \ 'matplotlib==3.8.1' 'pydantic==1.10.8' 'ortools==9.7.2996' 'requests==2.31.0'\
          \ 'boto3' 'shap' 'optuna' 'optbinning' 'urllib3' 'minio' 'lightgbm' 'python-dotenv'\
          \ && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef modeling(\n    train_csv: InputPath(Dataset),\n    test_csv:\
          \ InputPath(Dataset),\n    model_joblib: Output[Model],\n    registered_model:\
          \ OutputPath(str),\n    minio_endpoint: str,\n    minio_access_key: str,\n\
          \    minio_secret_key: str,\n    model_name: str = \"xgb\",\n    version:\
          \ str = \"v1\",\n    experiment_name: str = \"UnderwritingPipeline\",\n\
          ):\n    import os, json, optuna, shap, matplotlib.pyplot as plt, joblib\n\
          \    import pandas as pd, mlflow, xgboost as xgb\n    from lightgbm import\
          \ LGBMClassifier\n    from pathlib import Path\n    from sklearn.model_selection\
          \ import train_test_split\n    from sklearn.metrics import (\n        accuracy_score,\
          \ classification_report,\n        roc_auc_score, roc_curve, auc,\n    )\n\
          \    import mlflow.xgboost, mlflow.lightgbm\n\n    # Configure MLflow \u2192\
          \ MinIO\n    os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = f\"http://{minio_endpoint}\"\
          \n    os.environ[\"AWS_ACCESS_KEY_ID\"]      = minio_access_key\n    os.environ[\"\
          AWS_SECRET_ACCESS_KEY\"]  = minio_secret_key\n\n    # Load processed CSV\n\
          \    df = pd.read_csv(train_csv)\n    X, y = df.drop(\"TARGET\", axis=1),\
          \ df[\"TARGET\"]\n\n    # Optuna tuning\n    def objective(trial):\n   \
          \     params = {\n            \"max_depth\": trial.suggest_int(\"max_depth\"\
          , 2, 8),\n            \"learning_rate\": trial.suggest_float(\"learning_rate\"\
          , 1e-3, 0.3, log=True),\n            \"n_estimators\": trial.suggest_int(\"\
          n_estimators\", 100, 300),\n            \"subsample\": trial.suggest_float(\"\
          subsample\", 0.5, 1.0),\n            \"colsample_bytree\": trial.suggest_float(\"\
          colsample_bytree\", 0.5, 1.0),\n        }\n        clf = (\n           \
          \ xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"auc\", **params)\n\
          \            if model_name == \"xgb\"\n            else LGBMClassifier(**params)\n\
          \        )\n        X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.2,\
          \ random_state=42)\n        clf.fit(X_tr, y_tr)\n        return accuracy_score(y_val,\
          \ clf.predict(X_val))\n\n    study = optuna.create_study(direction=\"maximize\"\
          )\n    study.optimize(objective, n_trials=5)\n    best_params = study.best_params\n\
          \n    # Final train\n    clf = (\n        xgb.XGBClassifier(use_label_encoder=False,\
          \ eval_metric=\"auc\", **best_params)\n        if model_name == \"xgb\"\n\
          \        else LGBMClassifier(**best_params)\n    )\n    clf.fit(X, y)\n\n\
          \    # Dump model artifact\n    Path(model_joblib.path).parent.mkdir(parents=True,\
          \ exist_ok=True)\n    joblib.dump(clf, model_joblib.path)\n\n    # Evaluate\
          \ & prepare artifacts\n    preds  = clf.predict(X)\n    acc    = accuracy_score(y,\
          \ preds)\n    report = classification_report(y, preds)\n    try:\n     \
          \   proba      = clf.predict_proba(X)[:, 1]\n        roc        = roc_auc_score(y,\
          \ proba)\n        fpr, tpr, _ = roc_curve(y, proba)\n        roc_manual\
          \ = auc(fpr, tpr)\n    except:\n        roc = roc_manual = None\n\n    art_dir\
          \ = \"/tmp/artifacts\"\n    Path(art_dir).mkdir(parents=True, exist_ok=True)\n\
          \    (Path(art_dir) / \"report.txt\").write_text(report)\n\n    explainer\
          \ = shap.Explainer(clf)\n    shap_vals = explainer(X)\n    plt.figure()\n\
          \    shap.summary_plot(shap_vals, X, show=False)\n    plt.savefig(f\"{art_dir}/shap.png\"\
          )\n    plt.close()\n\n    (Path(art_dir) / \"schema.json\").write_text(\n\
          \        json.dumps(X.dtypes.apply(str).to_dict(), indent=2)\n    )\n\n\
          \    # Log & register via MLflow\n    mlflow.set_tracking_uri(\"http://mlflow.mlflow.svc.cluster.local:5000\"\
          )\n    mlflow.set_experiment(experiment_name)\n    run_name = f\"{version}_{model_name.upper()}\"\
          \n    with mlflow.start_run(run_name=run_name):\n        mlflow.log_params(best_params)\n\
          \        mlflow.log_metric(\"accuracy\", acc)\n        if roc is not None:\n\
          \            mlflow.log_metric(\"roc_auc\", roc)\n        if roc_manual\
          \ is not None:\n            mlflow.log_metric(\"roc_auc_manual\", roc_manual)\n\
          \n        mlflow.log_artifacts(art_dir, artifact_path=\"metrics\")\n\n \
          \       # log model (no need to capture return value)\n        if model_name\
          \ == \"xgb\":\n            mlflow.xgboost.log_model(clf, \"model\")\n  \
          \      else:\n            mlflow.lightgbm.log_model(clf, \"model\")\n\n\
          \        # now register using the artifact URI string\n        model_uri\
          \ = mlflow.get_artifact_uri(\"model\")\n        mlflow.register_model(model_uri,\
          \ run_name)\n\n    # Emit registered model name\n    Path(registered_model).write_text(run_name)\n\
          \n"
        image: microwave1005/scipy-img:latest
pipelineInfo:
  name: modeling
root:
  dag:
    outputs:
      artifacts:
        model_joblib:
          artifactSelectors:
          - outputArtifactKey: model_joblib
            producerSubtask: modeling
      parameters:
        registered_model:
          valueFromParameter:
            outputParameterKey: registered_model
            producerSubtask: modeling
    tasks:
      modeling:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-modeling
        inputs:
          artifacts:
            test_csv:
              componentInputArtifact: test_csv
            train_csv:
              componentInputArtifact: train_csv
          parameters:
            experiment_name:
              componentInputParameter: experiment_name
            minio_access_key:
              componentInputParameter: minio_access_key
            minio_endpoint:
              componentInputParameter: minio_endpoint
            minio_secret_key:
              componentInputParameter: minio_secret_key
            model_name:
              componentInputParameter: model_name
            version:
              componentInputParameter: version
        taskInfo:
          name: modeling
  inputDefinitions:
    artifacts:
      test_csv:
        artifactType:
          schemaTitle: system.Dataset
          schemaVersion: 0.0.1
      train_csv:
        artifactType:
          schemaTitle: system.Dataset
          schemaVersion: 0.0.1
    parameters:
      experiment_name:
        defaultValue: UnderwritingPipeline
        isOptional: true
        parameterType: STRING
      minio_access_key:
        parameterType: STRING
      minio_endpoint:
        parameterType: STRING
      minio_secret_key:
        parameterType: STRING
      model_name:
        defaultValue: xgb
        isOptional: true
        parameterType: STRING
      version:
        defaultValue: v1
        isOptional: true
        parameterType: STRING
  outputDefinitions:
    artifacts:
      model_joblib:
        artifactType:
          schemaTitle: system.Model
          schemaVersion: 0.0.1
    parameters:
      registered_model:
        parameterType: STRING
schemaVersion: 2.1.0
sdkVersion: kfp-2.12.1
