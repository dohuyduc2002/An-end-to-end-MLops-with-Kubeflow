# PIPELINE DEFINITION
# Name: preprocess-train
# Description: Pipeline with MinIO-backed CSV exchange.
# Inputs:
#    bucket_name: str
#    dest_test_object: str [Default: 'data/data/test/preprocessed_test.csv']
#    dest_train_object: str [Default: 'data/data/train/preprocessed_train.csv']
#    experiment_name: str [Default: 'UnderwritingPipeline']
#    minio_access_key: str
#    minio_endpoint: str
#    minio_secret_key: str
#    model_name: str [Default: 'xgb']
#    n_features_to_select: str [Default: 'auto']
#    test_object_name: str
#    train_object_name: str
#    version: str [Default: 'v1']
components:
  comp-preprocess-and-push:
    executorLabel: exec-preprocess-and-push
    inputDefinitions:
      parameters:
        bucket_name:
          parameterType: STRING
        data_version:
          defaultValue: v1
          isOptional: true
          parameterType: STRING
        dest_test_object:
          parameterType: STRING
        dest_train_object:
          parameterType: STRING
        minio_access_key:
          parameterType: STRING
        minio_endpoint:
          parameterType: STRING
        minio_secret_key:
          parameterType: STRING
        n_features_to_select:
          defaultValue: auto
          isOptional: true
          parameterType: STRING
        test_object_name:
          parameterType: STRING
        train_object_name:
          parameterType: STRING
    outputDefinitions:
      parameters:
        test_key:
          parameterType: STRING
        train_key:
          parameterType: STRING
  comp-train-and-register:
    executorLabel: exec-train-and-register
    inputDefinitions:
      parameters:
        bucket_name:
          parameterType: STRING
        experiment_name:
          defaultValue: UnderwritingPipeline
          isOptional: true
          parameterType: STRING
        minio_access_key:
          parameterType: STRING
        minio_endpoint:
          parameterType: STRING
        minio_secret_key:
          parameterType: STRING
        model_name:
          defaultValue: xgb
          isOptional: true
          parameterType: STRING
        processed_test_key:
          parameterType: STRING
        processed_train_key:
          parameterType: STRING
        version:
          defaultValue: v1
          isOptional: true
          parameterType: STRING
deploymentSpec:
  executors:
    exec-preprocess-and-push:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - preprocess_and_push
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef preprocess_and_push(\n    minio_endpoint: str,\n    minio_access_key:\
          \ str,\n    minio_secret_key: str,\n    bucket_name: str,\n    train_object_name:\
          \ str,\n    test_object_name: str,\n    dest_train_object: str,\n    dest_test_object:\
          \ str,\n    n_features_to_select: str = \"auto\",\n    data_version: str\
          \ = \"v1\",\n) -> NamedTuple(\"OutputKeys\", [(\"train_key\", str), (\"\
          test_key\", str)]):\n    import os, pandas as pd, numpy as np\n    from\
          \ pathlib import Path\n    from minio import Minio\n    from optbinning\
          \ import BinningProcess\n    from sklearn.feature_selection import SelectKBest,\
          \ f_classif\n\n    client = Minio(minio_endpoint, access_key=minio_access_key,\n\
          \                   secret_key=minio_secret_key, secure=False)\n\n    tmp\
          \ = \"/tmp/data\"\n    Path(tmp).mkdir(exist_ok=True)\n    local_tr = Path(tmp)\
          \ / Path(train_object_name).name\n    local_te = Path(tmp) / Path(test_object_name).name\n\
          \    client.fget_object(bucket_name, train_object_name, str(local_tr))\n\
          \    client.fget_object(bucket_name, test_object_name, str(local_te))\n\n\
          \    df_tr = pd.read_csv(local_tr)\n    df_te = pd.read_csv(local_te)\n\n\
          \    def get_feature_lists(df):\n        num_cols = df.select_dtypes(include=[\"\
          int64\", \"float64\"]).columns.tolist()\n        cat_cols = df.select_dtypes(include=[\"\
          object\"]).columns.tolist()\n        for c in (\"SK_ID_CURR\", \"TARGET\"\
          ):\n            if c in num_cols: num_cols.remove(c)\n        return cat_cols,\
          \ num_cols\n\n    def compute_iv(bins, target):\n        df = pd.DataFrame({\"\
          b\": bins, \"t\": target})\n        tot_g, tot_b = (df.t == 0).sum(), (df.t\
          \ == 1).sum()\n        iv = 0\n        for _, g in df.groupby(\"b\"):\n\
          \            good, bad = (g.t == 0).sum() or 0.5, (g.t == 1).sum() or 0.5\n\
          \            iv += (good/tot_g - bad/tot_b) * np.log((good/tot_g) / (bad/tot_b))\n\
          \        return iv\n\n    cat, num = get_feature_lists(df_tr)\n    y_tr\
          \ = df_tr[\"TARGET\"]\n    X_tr, X_te = df_tr.drop(\"TARGET\", axis=1),\
          \ df_te.copy()\n\n    survivors = []\n    for feat in cat + num:\n     \
          \   bp1 = BinningProcess([feat], categorical_variables=[feat] if feat in\
          \ cat else [])\n        bp1.fit(X_tr[[feat]].values, y_tr)\n        bins\
          \ = bp1.transform(X_tr[[feat]].values).flatten()\n        if 0.02 <= compute_iv(bins,\
          \ y_tr) <= 0.5 and X_tr[feat].isna().mean() <= 0.1:\n            survivors.append(feat)\n\
          \n    bp = BinningProcess(variable_names=survivors,\n                  \
          \      categorical_variables=[c for c in survivors if c in cat])\n    bp.fit(X_tr[survivors].values,\
          \ y_tr)\n    df_tr_b = pd.DataFrame(bp.transform(X_tr[survivors].values),\
          \ columns=survivors)\n    df_te_b = pd.DataFrame(bp.transform(X_te[survivors].values),\
          \ columns=survivors)\n\n    k = len(survivors) if n_features_to_select ==\
          \ \"auto\" else int(n_features_to_select)\n    selector = SelectKBest(f_classif,\
          \ k=k)\n    selector.fit(df_tr_b.fillna(0), y_tr)\n\n    keep = df_tr_b.columns[selector.get_support()]\n\
          \    out_tr = pd.DataFrame(selector.transform(df_tr_b), columns=keep)\n\
          \    out_te = pd.DataFrame(selector.transform(df_te_b), columns=keep)\n\
          \    out_tr[\"TARGET\"] = y_tr\n\n    train_key = dest_train_object.replace(\"\
          .csv\", f\"_{data_version}.csv\")\n    test_key = dest_test_object.replace(\"\
          .csv\", f\"_{data_version}.csv\")\n    out_tr_path, out_te_path = f\"/tmp/{Path(train_key).name}\"\
          , f\"/tmp/{Path(test_key).name}\"\n    out_tr.to_csv(out_tr_path, index=False)\n\
          \    out_te.to_csv(out_te_path, index=False)\n    client.fput_object(bucket_name,\
          \ train_key, out_tr_path)\n    client.fput_object(bucket_name, test_key,\
          \ out_te_path)\n\n    return (train_key, test_key)\n\n"
        image: microwave1005/scipy-img:latest
    exec-train-and-register:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - train_and_register
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef train_and_register(\n    minio_endpoint: str,\n    minio_access_key:\
          \ str,\n    minio_secret_key: str,\n    bucket_name: str,\n    processed_train_key:\
          \ str,\n    processed_test_key: str,\n    model_name: str = \"xgb\",\n \
          \   version: str = \"v1\",\n    experiment_name: str = \"UnderwritingPipeline\"\
          ,\n):\n    import os, json, optuna, shap, matplotlib.pyplot as plt\n   \
          \ import pandas as pd, mlflow, xgboost as xgb\n    from lightgbm import\
          \ LGBMClassifier\n    from tempfile import NamedTemporaryFile, mkdtemp\n\
          \    from minio import Minio\n    from sklearn.model_selection import train_test_split\n\
          \    from sklearn.metrics import (\n        accuracy_score, classification_report,\n\
          \        roc_auc_score, roc_curve, auc,\n    )\n    import mlflow.xgboost,\
          \ mlflow.lightgbm\n\n    # ---------- make MinIO the backend for MLflow\
          \ artifacts ----------\n    os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = f\"\
          http://{minio_endpoint}\"\n    os.environ[\"AWS_ACCESS_KEY_ID\"]      =\
          \ minio_access_key\n    os.environ[\"AWS_SECRET_ACCESS_KEY\"]  = minio_secret_key\n\
          \n    # ---------- fetch the two CSVs from MinIO ------------------------\n\
          \    client   = Minio(minio_endpoint,\n                     access_key=minio_access_key,\n\
          \                     secret_key=minio_secret_key,\n                   \
          \  secure=False)\n    tmp_dir  = mkdtemp()\n    local_tr = os.path.join(tmp_dir,\
          \ \"train.csv\")\n    local_te = os.path.join(tmp_dir, \"test.csv\")\n \
          \   client.fget_object(bucket_name, processed_train_key, local_tr)\n   \
          \ client.fget_object(bucket_name, processed_test_key,  local_te)\n\n   \
          \ df_train = pd.read_csv(local_tr)\n    df_test  = pd.read_csv(local_te)\n\
          \n    y_train  = df_train[\"TARGET\"]\n    X_train  = df_train.drop(columns=[\"\
          TARGET\"])\n    X_test   = df_test                             # test has\
          \ no TARGET\n\n    # ----------------------------------------------------------------\n\
          \    class UnderWritingModel:\n        def __init__(self, X_tr, y_tr, X_te):\n\
          \            self.X_train, self.y_train = X_tr, y_tr\n            self.X_test\
          \                = X_te\n            self.best_params, self.model = {},\
          \ None\n\n        # (unchanged) -------------------------------------------------\n\
          \        def train(self, model_type: str):\n            X_tr, X_val, y_tr,\
          \ y_val = train_test_split(\n                self.X_train, self.y_train,\
          \ test_size=0.2, random_state=42\n            )\n\n            def objective(trial):\n\
          \                p = {\n                    \"max_depth\": trial.suggest_int(\"\
          max_depth\", 2, 8),\n                    \"learning_rate\": trial.suggest_float(\"\
          learning_rate\", 1e-3, 0.3, log=True),\n                    \"n_estimators\"\
          : trial.suggest_int(\"n_estimators\", 100, 300),\n                    \"\
          subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n           \
          \         \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\"\
          , 0.5, 1.0),\n                }\n                model = (\n           \
          \         xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"auc\"\
          , **p)\n                    if model_type == \"xgb\" else\n            \
          \        LGBMClassifier(**p)\n                )\n                model.fit(X_tr,\
          \ y_tr)\n                return accuracy_score(y_val, model.predict(X_val))\n\
          \n            study = optuna.create_study(direction=\"maximize\")\n    \
          \        study.optimize(lambda t: objective(t), n_trials=5)\n\n        \
          \    self.best_params = study.best_params\n            self.model = (\n\
          \                xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"\
          auc\", **self.best_params)\n                if model_type == \"xgb\" else\n\
          \                LGBMClassifier(**self.best_params)\n            )\n   \
          \         self.model.fit(self.X_train, self.y_train)\n\n        # ----------------\
          \ FIX starts here ----------------------------\n        def log_and_register(self,\
          \ model_type: str, version: str):\n            # use a *labelled* set for\
          \ all metrics\n            X_eval, y_eval = self.X_train, self.y_train\n\
          \n            preds = self.model.predict(X_eval)\n            acc   = accuracy_score(y_eval,\
          \ preds)\n            report = classification_report(y_eval, preds)\n\n\
          \            try:\n                probas = self.model.predict_proba(X_eval)[:,\
          \ 1]\n                roc    = roc_auc_score(y_eval, probas)\n         \
          \       fpr, tpr, _ = roc_curve(y_eval, probas)\n                roc_manual\
          \  = auc(fpr, tpr)\n            except Exception:\n                roc =\
          \ roc_manual = None\n\n            # ---------- write artefacts locally\
          \ ----------------------\n            os.makedirs(\"/tmp/artifacts\", exist_ok=True)\n\
          \n            rep_path = \"/tmp/artifacts/report.txt\"\n            with\
          \ open(rep_path, \"w\") as f:\n                f.write(report)\n\n     \
          \       shap_values = shap.Explainer(self.model)(X_eval)\n            shap_path\
          \ = \"/tmp/artifacts/shap.png\"\n            plt.figure()\n            shap.summary_plot(shap_values,\
          \ X_eval, show=False)\n            plt.savefig(shap_path); plt.close()\n\
          \n            schema_path = \"/tmp/artifacts/schema.json\"\n           \
          \ with open(schema_path, \"w\") as f:\n                json.dump(X_eval.dtypes.apply(str).to_dict(),\
          \ f, indent=2)\n\n            # ---------- MLflow logging --------------------------------\n\
          \            mlflow.set_tracking_uri(\"http://mlflow.mlflow.svc.cluster.local:5000\"\
          )\n            mlflow.set_experiment(experiment_name)\n\n            with\
          \ mlflow.start_run(run_name=f\"{version}_{model_type.upper()}\"):\n    \
          \            mlflow.log_params(self.best_params)\n                mlflow.log_metric(\"\
          accuracy\", acc)\n                if roc is not None:       mlflow.log_metric(\"\
          roc_auc\", roc)\n                if roc_manual is not None: mlflow.log_metric(\"\
          roc_auc_manual\", roc_manual)\n\n                mlflow.log_artifacts(\"\
          /tmp/artifacts\", artifact_path=\"metrics\")\n\n                if model_type\
          \ == \"xgb\":\n                    mlflow.xgboost.log_model(self.model,\
          \ \"model\")\n                else:\n                    mlflow.lightgbm.log_model(self.model,\
          \ \"model\")\n\n                mlflow.register_model(mlflow.get_artifact_uri(\"\
          model\"),\n                                      f\"{version}_{model_type.upper()}\"\
          )\n        # ---------------- FIX ends here ------------------------------\n\
          \n    # run the whole thing\n    uw = UnderWritingModel(X_train, y_train,\
          \ X_test)\n    uw.train(model_name)\n    uw.log_and_register(model_name,\
          \ version)\n\n"
        image: microwave1005/scipy-img:latest
pipelineInfo:
  description: Pipeline with MinIO-backed CSV exchange.
  name: preprocess-train
root:
  dag:
    tasks:
      preprocess-and-push:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-preprocess-and-push
        inputs:
          parameters:
            bucket_name:
              componentInputParameter: bucket_name
            data_version:
              componentInputParameter: version
            dest_test_object:
              componentInputParameter: dest_test_object
            dest_train_object:
              componentInputParameter: dest_train_object
            minio_access_key:
              componentInputParameter: minio_access_key
            minio_endpoint:
              componentInputParameter: minio_endpoint
            minio_secret_key:
              componentInputParameter: minio_secret_key
            n_features_to_select:
              componentInputParameter: n_features_to_select
            test_object_name:
              componentInputParameter: test_object_name
            train_object_name:
              componentInputParameter: train_object_name
        taskInfo:
          name: preprocess-and-push
      train-and-register:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-train-and-register
        dependentTasks:
        - preprocess-and-push
        inputs:
          parameters:
            bucket_name:
              componentInputParameter: bucket_name
            experiment_name:
              componentInputParameter: experiment_name
            minio_access_key:
              componentInputParameter: minio_access_key
            minio_endpoint:
              componentInputParameter: minio_endpoint
            minio_secret_key:
              componentInputParameter: minio_secret_key
            model_name:
              componentInputParameter: model_name
            processed_test_key:
              taskOutputParameter:
                outputParameterKey: test_key
                producerTask: preprocess-and-push
            processed_train_key:
              taskOutputParameter:
                outputParameterKey: train_key
                producerTask: preprocess-and-push
            version:
              componentInputParameter: version
        taskInfo:
          name: train-and-register
  inputDefinitions:
    parameters:
      bucket_name:
        parameterType: STRING
      dest_test_object:
        defaultValue: data/data/test/preprocessed_test.csv
        isOptional: true
        parameterType: STRING
      dest_train_object:
        defaultValue: data/data/train/preprocessed_train.csv
        isOptional: true
        parameterType: STRING
      experiment_name:
        defaultValue: UnderwritingPipeline
        isOptional: true
        parameterType: STRING
      minio_access_key:
        parameterType: STRING
      minio_endpoint:
        parameterType: STRING
      minio_secret_key:
        parameterType: STRING
      model_name:
        defaultValue: xgb
        isOptional: true
        parameterType: STRING
      n_features_to_select:
        defaultValue: auto
        isOptional: true
        parameterType: STRING
      test_object_name:
        parameterType: STRING
      train_object_name:
        parameterType: STRING
      version:
        defaultValue: v1
        isOptional: true
        parameterType: STRING
schemaVersion: 2.1.0
sdkVersion: kfp-2.12.1
